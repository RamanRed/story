{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RamanRed/story/blob/main/prompting_llms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb9oQ7F6nDwQ",
        "outputId": "da6edbf3-c851-4b93-910d-12331ca657c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-_7_hokhk\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-_7_hokhk\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 27903de7ecfc21e9b5a061c46c3b1ff73539d385\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.23.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.4.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (2024.7.4)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.45.0.dev0-py3-none-any.whl size=9583114 sha256=8d8b0c3d2403255889bb8d7a442e4e9e2b767756578aac8758f16a5bbf80dd90\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tgvr3qzm/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "Successfully installed transformers-4.45.0.dev0\n",
            "Collecting git+https://github.com/huggingface/accelerate.git\n",
            "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-wchlp6hl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-wchlp6hl\n",
            "  Resolved https://github.com/huggingface/accelerate.git to commit 939ce400cbc0478fd281b9fcc9a2a85691ba9f7d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.0.dev0) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.0.dev0) (2.4.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.0.dev0) (0.23.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.0.dev0) (0.4.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.34.0.dev0) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.34.0.dev0) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.34.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.34.0.dev0) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.34.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.0.dev0) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.0.dev0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.0.dev0) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.34.0.dev0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.34.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.34.0.dev0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.34.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.34.0.dev0) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.34.0.dev0) (1.3.0)\n",
            "Building wheels for collected packages: accelerate\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for accelerate: filename=accelerate-0.34.0.dev0-py3-none-any.whl size=324168 sha256=a98c7a1df75226fd11bf8655c15352c8bca630dfc21ef7490458df916bd1313b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jhfyv1_3/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\n",
            "Successfully built accelerate\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.32.1\n",
            "    Uninstalling accelerate-0.32.1:\n",
            "      Successfully uninstalled accelerate-0.32.1\n",
            "Successfully installed accelerate-0.34.0.dev0\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.3\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install git+https://github.com/huggingface/accelerate.git\n",
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AyYmOI9nH6D"
      },
      "outputs": [],
      "source": [
        "# importing the packages\n",
        "import torch\n",
        "import warnings\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592,
          "referenced_widgets": [
            "2c84aa378731477b90e9ca50e9fb4c0a",
            "5d94f568bb1c485f89278b0b6edf0168",
            "a47afbe4ec2646e3809ccfcf250a792f",
            "46f99d659466425d894353261dc5b2ba",
            "8b2d981eb7fe4241a766123f994b6ab8",
            "60d91ee3d89b4311b1d28681e1a51fb1",
            "2edacadac182442683fbbe35c97c3b3f",
            "8580d2b9e75a4c0a9ea8be0e26692cc2",
            "68361610782e4f17a26f07debd4dea5b",
            "8371360ccccf445c912d635410f4af87",
            "d556fdf61cd14443970aab252e9e5377"
          ]
        },
        "id": "oPUU6MMwnJiM",
        "outputId": "4a2e062f-8d19-4e30-cb3a-3f61bf29c6da"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c84aa378731477b90e9ca50e9fb4c0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "PackageNotFoundError",
          "evalue": "No package metadata was found for bitsandbytes",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0cb7e9fe4d8f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# loading the model from huggingface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'NousResearch/Llama-2-7b-chat-hf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mload_in_4bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m                                                            \u001b[0;31m# loading the model with 4 bit precision, so as to show the example on Colab GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3331\u001b[0m             \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBitsAndBytesConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3332\u001b[0m             \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"load_in_4bit\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_in_4bit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"load_in_8bit\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_in_8bit\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3333\u001b[0;31m             quantization_config, kwargs = BitsAndBytesConfig.from_dict(\n\u001b[0m\u001b[1;32m   3334\u001b[0m                 \u001b[0mconfig_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3335\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/quantization_config.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[0;34m(cls, config_dict, return_unused_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mto_remove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/quantization_config.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load_in_8bit, load_in_4bit, llm_int8_threshold, llm_int8_skip_modules, llm_int8_enable_fp32_cpu_offload, llm_int8_has_fp16_weight, bnb_4bit_compute_dtype, bnb_4bit_quant_type, bnb_4bit_use_double_quant, bnb_4bit_quant_storage, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unused kwargs: {list(kwargs.keys())}. These kwargs are not used in {self.__class__}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/quantization_config.py\u001b[0m in \u001b[0;36mpost_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bnb_4bit_use_double_quant must be a boolean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         if self.load_in_4bit and not version.parse(importlib.metadata.version(\"bitsandbytes\")) >= version.parse(\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0;34m\"0.39.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         ):\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mversion\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0;34m\"Version\"\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m     \"\"\"\n\u001b[0;32m--> 996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mdistribution\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0mthereof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \"\"\"\n\u001b[0;32m--> 969\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfrom_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    546\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPackageNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPackageNotFoundError\u001b[0m: No package metadata was found for bitsandbytes",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# loading the model from huggingface\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    'NousResearch/Llama-2-7b-chat-hf',\n",
        "    load_in_4bit=True,                                                            # loading the model with 4 bit precision, so as to show the example on Colab GPU\n",
        "    device_map='auto'\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained('NousResearch/Llama-2-7b-chat-hf')\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQqgiJq3oLQ3",
        "outputId": "5770c0af-49ff-4ddb-b19a-d6e7149a5e8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaConfig {\n",
              "  \"_name_or_path\": \"NousResearch/Llama-2-7b-chat-hf\",\n",
              "  \"architectures\": [\n",
              "    \"LlamaForCausalLM\"\n",
              "  ],\n",
              "  \"attention_bias\": false,\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 1,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"head_dim\": 128,\n",
              "  \"hidden_act\": \"silu\",\n",
              "  \"hidden_size\": 4096,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 11008,\n",
              "  \"max_position_embeddings\": 4096,\n",
              "  \"mlp_bias\": false,\n",
              "  \"model_type\": \"llama\",\n",
              "  \"num_attention_heads\": 32,\n",
              "  \"num_hidden_layers\": 32,\n",
              "  \"num_key_value_heads\": 32,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"pretraining_tp\": 1,\n",
              "  \"quantization_config\": {\n",
              "    \"_load_in_4bit\": true,\n",
              "    \"_load_in_8bit\": false,\n",
              "    \"bnb_4bit_compute_dtype\": \"float32\",\n",
              "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
              "    \"bnb_4bit_quant_type\": \"fp4\",\n",
              "    \"bnb_4bit_use_double_quant\": false,\n",
              "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
              "    \"llm_int8_has_fp16_weight\": false,\n",
              "    \"llm_int8_skip_modules\": null,\n",
              "    \"llm_int8_threshold\": 6.0,\n",
              "    \"load_in_4bit\": true,\n",
              "    \"load_in_8bit\": false,\n",
              "    \"quant_method\": \"bitsandbytes\"\n",
              "  },\n",
              "  \"rms_norm_eps\": 1e-05,\n",
              "  \"rope_scaling\": null,\n",
              "  \"rope_theta\": 10000.0,\n",
              "  \"tie_word_embeddings\": false,\n",
              "  \"torch_dtype\": \"float16\",\n",
              "  \"transformers_version\": \"4.45.0.dev0\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 32000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYDqmjzpnPaM"
      },
      "outputs": [],
      "source": [
        "# setting the model generation configuration\n",
        "generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    temperature = 0.8,\n",
        "    repetition_penalty = 1.5,\n",
        "    max_new_tokens = 256\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkJpUljFnnL2"
      },
      "source": [
        "# Zero Shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdToErknnL8-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba7fd08-9d19-4ef4-ca2f-f0e736a6dfc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    1,   306, 29915,   645,  1010,   278,  4863,  3748,   338,   394,\n",
            "           327,   901,  2090,  1135,   278,  2706,  7790, 29903,   296,  2073,\n",
            "         29901]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(\"I'll bet the video game is alot more fun than the film.\\Sentiment:\", return_tensors=\"pt\")\n",
        "print(inputs)\n",
        "input_ids = inputs[\"input_ids\"].to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RqzuPJgg0S1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e6db46-1781-44cb-fc23-8f02996587e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
          ]
        }
      ],
      "source": [
        "# passing the prompt tokens to the generative model to generate the response tokens\n",
        "with torch.no_grad():\n",
        "    generation_output = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=torch.ones_like(input_ids),\n",
        "        generation_config=generation_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzBAHmj2nS_4",
        "outputId": "5bef2ad8-9a77-4b4d-a93a-73ada835fa2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'll bet the video game is alot more fun than the film.\\Sentiment: 0. surely\\\n",
            "Too lazy to write a full review, but here are some quick thoughts on Sonic Forces:\\nThe good stuff first - visually this game looks absolutely incredible in both handheld and docked modes (even better when you see it running at high framerates). The character models especially look amazing with all their animations captured perfectly down to even small details like blinking or moving around naturally while walking/running,\\nNow for the not-so-good parts...the story mode feels very forced as if they were trying too hard making every cutscene feel cringe worthy without any real emotional weight behind them; characters come off feeling one dimensionally blandly personalityless most times unless voiced by someone talented outside of gaming who knows how deal with difficult dialogue mandated from above (\\\"Hey remember that thing we did back then? That was pretty cool yeah! *cough*\"). Not only does no attempt go into fleshing anything meaningful onto these shallow cardboard caracatures aside maybe two main exceptions.\", \"and there lies part issue number three---these exceptional sidekicks don’t fully become playable until almost twenty hours gone past your initial completion date\n"
          ]
        }
      ],
      "source": [
        "# decode the model generated tokens, and printing the generated output.\n",
        "output_text = tokenizer.decode(generation_output[0].cuda(), skip_special_tokens=True).strip()\n",
        "print(output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdT5Spjqnp4v"
      },
      "source": [
        "# Few Shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4jPsFYcnrr2"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer('''\n",
        "Text: (lawrence bounces) all over the stage, dancing, running, sweating, mopping his face and generally displaying the wacky talent that brought him fame in the first place.\n",
        "Sentiment: positive\n",
        "\n",
        "Text: despite all evidence to the contrary, this clunker has somehow managed to pose as an actual feature movie, the kind that charges full admission and gets hyped on\n",
        "tv and purports to amuse small children and ostensible adults.\n",
        "Sentiment: negative\n",
        "\n",
        "Text: for the first time in years, de niro digs deep emotionally, perhaps because he's been stirred by the powerful work of his co-stars.\n",
        "Sentiment: positive\n",
        "\n",
        "Text: i'll bet the video game is a lot more fun than the film.\n",
        "\\Sentiment:''', return_tensors=\"pt\")\n",
        "input_ids = inputs[\"input_ids\"].to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoXSIOStg1pT"
      },
      "outputs": [],
      "source": [
        "# passing the prompt tokens to the generative model to generate the response tokens\n",
        "with torch.no_grad():\n",
        "    generation_output = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=torch.ones_like(input_ids),\n",
        "        generation_config=generation_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BwcTlhKoRD0",
        "outputId": "efbe1c2d-f0f8-49d9-e6dc-e674fb303c6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: (lawrence bounces) all over the stage, dancing, running, sweating, mopping his face and generally displaying the wacky talent that brought him fame in the first place.\n",
            "Sentiment: positive\n",
            "\n",
            "Text: despite all evidence to the contrary, this clunker has somehow managed to pose as an actual feature movie, the kind that charges full admission and gets hyped on\n",
            "tv and purports to amuse small children and ostensible adults.\n",
            "Sentiment: negative\n",
            "\n",
            "Text: for the first time in years, de niro digs deep emotionally, perhaps because he's been stirred by the powerful work of his co-stars.\n",
            "Sentiment: positive\n",
            "\n",
            "Text: i'll bet the video game is a lot more fun than the film.\n",
            "\\Sentiment: neutral\n"
          ]
        }
      ],
      "source": [
        "# decode the model generated tokens, and printing the generated output.\n",
        "output_text = tokenizer.decode(generation_output[0].cuda(), skip_special_tokens=True).strip()\n",
        "print(output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa6ZfM-nnsP7"
      },
      "source": [
        "# Instruct Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_yAv9g5nuFA"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer('''Please label the sentiment towards the movie of the given movie review. The sentiment label should be \"positive\" or \"negative\".\n",
        "Text: i'll bet the video game is a lot more fun than the film.\n",
        "\\Sentiment:''', return_tensors=\"pt\")\n",
        "input_ids = inputs[\"input_ids\"].to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9Wj1qneg2R5"
      },
      "outputs": [],
      "source": [
        "# passing the prompt tokens to the generative model to generate the response tokens\n",
        "with torch.no_grad():\n",
        "    generation_output = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=torch.ones_like(input_ids),\n",
        "        generation_config=generation_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hnxb_AurojLs",
        "outputId": "26e15de9-fae4-4775-edaf-42790d0dc839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please label the sentiment towards the movie of the given movie review. The sentiment label should be \"positive\" or \"negative\".\n",
            "Text: i'll bet the video game is a lot more fun than the film.\n",
            "\\Sentiment: Positive\n"
          ]
        }
      ],
      "source": [
        "# decode the model generated tokens, and printing the generated output.\n",
        "output_text = tokenizer.decode(generation_output[0].cuda(), skip_special_tokens=True).strip()\n",
        "print(output_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EGn1h4htLe_j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c84aa378731477b90e9ca50e9fb4c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d94f568bb1c485f89278b0b6edf0168",
              "IPY_MODEL_a47afbe4ec2646e3809ccfcf250a792f",
              "IPY_MODEL_46f99d659466425d894353261dc5b2ba"
            ],
            "layout": "IPY_MODEL_8b2d981eb7fe4241a766123f994b6ab8"
          }
        },
        "5d94f568bb1c485f89278b0b6edf0168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60d91ee3d89b4311b1d28681e1a51fb1",
            "placeholder": "​",
            "style": "IPY_MODEL_2edacadac182442683fbbe35c97c3b3f",
            "value": "config.json: 100%"
          }
        },
        "a47afbe4ec2646e3809ccfcf250a792f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8580d2b9e75a4c0a9ea8be0e26692cc2",
            "max": 583,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68361610782e4f17a26f07debd4dea5b",
            "value": 583
          }
        },
        "46f99d659466425d894353261dc5b2ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8371360ccccf445c912d635410f4af87",
            "placeholder": "​",
            "style": "IPY_MODEL_d556fdf61cd14443970aab252e9e5377",
            "value": " 583/583 [00:00&lt;00:00, 22.6kB/s]"
          }
        },
        "8b2d981eb7fe4241a766123f994b6ab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60d91ee3d89b4311b1d28681e1a51fb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2edacadac182442683fbbe35c97c3b3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8580d2b9e75a4c0a9ea8be0e26692cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68361610782e4f17a26f07debd4dea5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8371360ccccf445c912d635410f4af87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d556fdf61cd14443970aab252e9e5377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}